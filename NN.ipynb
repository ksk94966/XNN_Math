{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO23tt7Q4bCzcqtmXE8Hs7c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksk94966/XNN_Math/blob/master/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct1oP-ACslzA"
      },
      "source": [
        "import os.path\n",
        "import urllib.request\n",
        "import gzip\n",
        "import math\n",
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data\n",
        "DATA_NUM_TRAIN         = 60000\n",
        "DATA_NUM_TEST          = 10000\n",
        "DATA_CHANNELS          = 1\n",
        "DATA_ROWS              = 28\n",
        "DATA_COLS              = 28\n",
        "DATA_CLASSES           = 10\n",
        "DATA_URL_TRAIN_DATA    = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "DATA_URL_TRAIN_LABELS  = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "DATA_URL_TEST_DATA     = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "DATA_URL_TEST_LABELS   = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "DATA_FILE_TRAIN_DATA   = 'train_data.gz'\n",
        "DATA_FILE_TRAIN_LABELS = 'train_labels.gz'\n",
        "DATA_FILE_TEST_DATA    = 'test_data.gz'\n",
        "DATA_FILE_TEST_LABELS  = 'test_labels.gz'\n",
        "\n",
        "# display\n",
        "DISPLAY_ROWS   = 8\n",
        "DISPLAY_COLS   = 4\n",
        "DISPLAY_COL_IN = 10\n",
        "DISPLAY_ROW_IN = 25\n",
        "DISPLAY_NUM    = DISPLAY_ROWS*DISPLAY_COLS\n",
        "\n",
        "# download\n",
        "if (os.path.exists(DATA_FILE_TRAIN_DATA)   == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_DATA,   DATA_FILE_TRAIN_DATA)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_LABELS) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_LABELS, DATA_FILE_TRAIN_LABELS)\n",
        "if (os.path.exists(DATA_FILE_TEST_DATA)    == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_DATA,    DATA_FILE_TEST_DATA)\n",
        "if (os.path.exists(DATA_FILE_TEST_LABELS)  == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_LABELS,  DATA_FILE_TEST_LABELS)\n",
        "\n",
        "# training data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_train_data   = gzip.open(DATA_FILE_TRAIN_DATA, 'r')\n",
        "file_train_data.read(16)\n",
        "buffer_train_data = file_train_data.read(DATA_NUM_TRAIN*DATA_ROWS*DATA_COLS)\n",
        "train_data        = np.frombuffer(buffer_train_data, dtype=np.uint8).astype(np.float32)\n",
        "train_data        = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# training labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_train_labels   = gzip.open(DATA_FILE_TRAIN_LABELS, 'r')\n",
        "file_train_labels.read(8)\n",
        "buffer_train_labels = file_train_labels.read(DATA_NUM_TRAIN)\n",
        "train_labels        = np.frombuffer(buffer_train_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# testing data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_test_data   = gzip.open(DATA_FILE_TEST_DATA, 'r')\n",
        "file_test_data.read(16)\n",
        "buffer_test_data = file_test_data.read(DATA_NUM_TEST*DATA_ROWS*DATA_COLS)\n",
        "test_data        = np.frombuffer(buffer_test_data, dtype=np.uint8).astype(np.float32)\n",
        "test_data        = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# testing labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_test_labels   = gzip.open(DATA_FILE_TEST_LABELS, 'r')\n",
        "file_test_labels.read(8)\n",
        "buffer_test_labels = file_test_labels.read(DATA_NUM_TEST)\n",
        "test_labels        = np.frombuffer(buffer_test_labels, dtype=np.uint8).astype(np.int32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygX7HRKtP4A",
        "outputId": "6c9299d9-b78d-466a-c723-1fd537fe68b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Printing dimensions\n",
        "print(train_data.shape)   # (60000, 1, 28, 28)\n",
        "print(train_labels.shape) # (60000,)\n",
        "print(test_data.shape)    # (10000, 1, 28, 28)\n",
        "print(test_labels.shape)  # (10000,)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1, 28, 28)\n",
            "(60000,)\n",
            "(10000, 1, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEvk6X1VW63S"
      },
      "source": [
        "lr = 0.5\n",
        "\n",
        "#hidden Layer1\n",
        "wh1 = np.random.rand(784,1000)\n",
        "bh1 = np.random.rand(1,1000)\n",
        "\n",
        "#hidden Layer2\n",
        "wh2 = np.random.rand(1000,100)\n",
        "bh2 = np.random.rand(1,100)\n",
        "\n",
        "#Output Layer\n",
        "wo = np.random.rand(100,10)\n",
        "bo = np.random.rand(1,10)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fzy5El4MfL"
      },
      "source": [
        "def multi1(v):\n",
        "  return np.dot(v,wh1)\n",
        "\n",
        "def multi2(v):\n",
        "  return np.dot(v,wh2)\n",
        "\n",
        "def multi3(v):\n",
        "  return np.dot(v,wo)\n",
        "\n",
        "def ReLU(x):\n",
        "  return np.maximum(x,0)\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def getLabelMatrix(i):\n",
        "  lab = np.zeros((1,10))\n",
        "  lab[0][i] = 1\n",
        "  return lab"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQrp7MZ84Ssa",
        "outputId": "76dcede6-e026-4017-e111-f0bfe997887e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "#Forward Pass\n",
        "for epoch in range(20):\n",
        "  a0 = train_data[epoch]/255.0                                                      #division by 255\n",
        "  a0 = a0.reshape(1,784)                                                                 #Reshaping ---> Vectorization\n",
        "\n",
        "  #Passing the sample through first hidden layer\n",
        "  zh1 = multi1(a0) + bh1                                                                    #Creating Zh1 which is addtion of weights and bias\n",
        "  ah1 = ReLU(zh1)                                                                                 #Generated hiddenlayer1 Activations\n",
        "  \n",
        "  #passing the h1 sample through second hiddden layer\n",
        "  zh2 = multi2(ah1) + bh2                                                                   #Creating Zh2 which is addtion of weights and bias\n",
        "  ah2 = ReLU(zh2)                                                                                #Generated hiddenlayer2 Activations \n",
        "\n",
        "  #passing the h2 sample through third hiddden layer\n",
        "  zo = multi3(ah2) + bo                                                                        #Creating Zo which is addtion of weights and bias\n",
        "  ao = softmax(zo)                                                                                #Generated output Activations\n",
        "  \n",
        "  #Here we are using entropy function as loss function\n",
        "\n",
        "  #BackPropagation----------------------------------------------------------\n",
        "\n",
        "  #phase 1\n",
        "\n",
        "  y = getLabelMatrix(test_labels[epoch])\n",
        "\n",
        "  dcost_dzo = ao - y                 #(1,10)\n",
        "  dzo_dwo = ah2.transpose()                      #(1,100)   --> we have to transpose this one\n",
        "\n",
        "  dcost_dwo = np.dot( dzo_dwo,dcost_dzo)                             #derivate of cost w.r.t output weights      #(100,10)\n",
        "\n",
        "  dcost_dbo = dcost_dzo                                                              #derivative of cost w.r.t bias                     #(1,10)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n",
            "(1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}