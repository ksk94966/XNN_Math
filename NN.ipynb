{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOcENsGza7tT9qgCsj96Mw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksk94966/XNN_Math/blob/master/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct1oP-ACslzA"
      },
      "source": [
        "import os.path\n",
        "import urllib.request\n",
        "import gzip\n",
        "import math\n",
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data\n",
        "DATA_NUM_TRAIN         = 60000\n",
        "DATA_NUM_TEST          = 10000\n",
        "DATA_CHANNELS          = 1\n",
        "DATA_ROWS              = 28\n",
        "DATA_COLS              = 28\n",
        "DATA_CLASSES           = 10\n",
        "DATA_URL_TRAIN_DATA    = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "DATA_URL_TRAIN_LABELS  = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "DATA_URL_TEST_DATA     = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "DATA_URL_TEST_LABELS   = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "DATA_FILE_TRAIN_DATA   = 'train_data.gz'\n",
        "DATA_FILE_TRAIN_LABELS = 'train_labels.gz'\n",
        "DATA_FILE_TEST_DATA    = 'test_data.gz'\n",
        "DATA_FILE_TEST_LABELS  = 'test_labels.gz'\n",
        "\n",
        "# display\n",
        "DISPLAY_ROWS   = 8\n",
        "DISPLAY_COLS   = 4\n",
        "DISPLAY_COL_IN = 10\n",
        "DISPLAY_ROW_IN = 25\n",
        "DISPLAY_NUM    = DISPLAY_ROWS*DISPLAY_COLS\n",
        "\n",
        "# download\n",
        "if (os.path.exists(DATA_FILE_TRAIN_DATA)   == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_DATA,   DATA_FILE_TRAIN_DATA)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_LABELS) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_LABELS, DATA_FILE_TRAIN_LABELS)\n",
        "if (os.path.exists(DATA_FILE_TEST_DATA)    == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_DATA,    DATA_FILE_TEST_DATA)\n",
        "if (os.path.exists(DATA_FILE_TEST_LABELS)  == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_LABELS,  DATA_FILE_TEST_LABELS)\n",
        "\n",
        "# training data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_train_data   = gzip.open(DATA_FILE_TRAIN_DATA, 'r')\n",
        "file_train_data.read(16)\n",
        "buffer_train_data = file_train_data.read(DATA_NUM_TRAIN*DATA_ROWS*DATA_COLS)\n",
        "train_data        = np.frombuffer(buffer_train_data, dtype=np.uint8).astype(np.float32)\n",
        "train_data        = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# training labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_train_labels   = gzip.open(DATA_FILE_TRAIN_LABELS, 'r')\n",
        "file_train_labels.read(8)\n",
        "buffer_train_labels = file_train_labels.read(DATA_NUM_TRAIN)\n",
        "train_labels        = np.frombuffer(buffer_train_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# testing data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_test_data   = gzip.open(DATA_FILE_TEST_DATA, 'r')\n",
        "file_test_data.read(16)\n",
        "buffer_test_data = file_test_data.read(DATA_NUM_TEST*DATA_ROWS*DATA_COLS)\n",
        "test_data        = np.frombuffer(buffer_test_data, dtype=np.uint8).astype(np.float32)\n",
        "test_data        = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# testing labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_test_labels   = gzip.open(DATA_FILE_TEST_LABELS, 'r')\n",
        "file_test_labels.read(8)\n",
        "buffer_test_labels = file_test_labels.read(DATA_NUM_TEST)\n",
        "test_labels        = np.frombuffer(buffer_test_labels, dtype=np.uint8).astype(np.int32)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygX7HRKtP4A",
        "outputId": "74d24cef-5cc4-4e91-eae9-d29cdca9c49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Printing dimensions\n",
        "print(train_data.shape)   # (60000, 1, 28, 28)\n",
        "print(train_labels.shape) # (60000,)\n",
        "print(test_data.shape)    # (10000, 1, 28, 28)\n",
        "print(test_labels.shape)  # (10000,)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1, 28, 28)\n",
            "(60000,)\n",
            "(10000, 1, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEvk6X1VW63S"
      },
      "source": [
        "lr = 0.5\n",
        "\n",
        "#hidden Layer1\n",
        "wh1 = np.random.rand(784,1000)/np.sqrt(784)\n",
        "bh1 = np.random.rand(1,1000)\n",
        "\n",
        "#hidden Layer2\n",
        "wh2 = np.random.rand(1000,100)/np.sqrt(1000)\n",
        "bh2 = np.random.rand(1,100)\n",
        "\n",
        "#Output Layer\n",
        "wo = np.random.rand(100,10)/np.sqrt(100)\n",
        "bo = np.random.rand(1,10)\n",
        "\n"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fzy5El4MfL"
      },
      "source": [
        "def multi1(v):\n",
        "  return np.dot(v,wh1)\n",
        "\n",
        "def multi2(v):\n",
        "  return np.dot(v,wh2)\n",
        "\n",
        "def multi3(v):\n",
        "  return np.dot(v,wo)\n",
        "\n",
        "def ReLU(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x /np.sum(e_x)\n",
        "\n",
        "def getLabelMatrix(i):\n",
        "  lab = np.zeros((1,10))\n",
        "  lab[0][i] = 1\n",
        "  return lab\n",
        "\n"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQrp7MZ84Ssa",
        "outputId": "900cf4cc-5f6f-449a-cdbd-b2116aab95cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Forward Pass\n",
        "for epoch in range(5000):\n",
        "  a0 = train_data[epoch]/255.0                                                      #division by 255\n",
        "  a0 = a0.reshape(1,784)                                                                 #Reshaping ---> Vectorization\n",
        "  # print(bh1)\n",
        "\n",
        "  #Passing the sample through first hidden layer\n",
        "  zh1 = np.add(multi1(a0) ,bh1)                                                                    #Creating Zh1 which is addtion of weights and bias\n",
        "  ah1 = ReLU(zh1)                                                                                 #Generated hiddenlayer1 Activations\n",
        "  # print(ah1)\n",
        "\n",
        "  #passing the h1 sample through second hiddden layer\n",
        "  zh2 = np.add(multi2(ah1), bh2)                                                                   #Creating Zh2 which is addtion of weights and bias\n",
        "  ah2 = ReLU(zh2)                                                                                #Generated hiddenlayer2 Activations \n",
        "  \n",
        "\n",
        "  #passing the h2 sample through third hiddden layer\n",
        "  zo = np.add(multi3(ah2) ,bo)                                                                        #Creating Zo which is addtion of weights and bias\n",
        "  ao = softmax(zo)                                                                                #Generated output Activations\n",
        "  #print(ao)\n",
        "  \n",
        "  #Here we are using entropy function as loss function\n",
        "\n",
        "  #BackPropagation----------------------------------------------------------\n",
        "\n",
        "  #phase 1              ---> for the output layer\n",
        "\n",
        "  y = getLabelMatrix(train_labels[epoch])\n",
        "  dcost_dzo = ao - y                                                                             #(1,10)\n",
        "  dzo_dwo = ah2.transpose()                                                            #(1,100)   --> we have to transpose this one\n",
        "\n",
        "  dcost_dwo = np.dot( dzo_dwo,dcost_dzo)                                 #derivate of cost w.r.t output weights      #(100,10)\n",
        "  dcost_dbo = dcost_dzo                                                                   #derivative of cost w.r.t bias                      #(1,10)\n",
        "\n",
        "  #phase 2          ---> for the hidden layer 2 \n",
        "  dzo_dah2 = wo\n",
        "  dcost_dah2 = np.dot(dcost_dzo , dzo_dah2.transpose())\n",
        "  dah2_dzh2 = reluDerivative(zh2)\n",
        "  dzh2_dwh2 = ah1\n",
        "  dcost_dwh2 = np.dot(dzh2_dwh2.T,dah2_dzh2*dcost_dah2)\n",
        "  dcost_dbh2 = dcost_dah2 * dah2_dzh2\n",
        "  #print(dcost_dwh2)\n",
        "\n",
        "\n",
        "  #phase 3   ---- > for hidden layer 1\n",
        "  dzh2_dah1 = wh2\n",
        "  dcost_dzh2 = dcost_dah2 * dah2_dzh2\n",
        "  dcost_dah1 = np.dot(dcost_dzh2,dzh2_dah1.transpose()) \n",
        "  dah1_dzh1 = reluDerivative(zh1)\n",
        "  dzh1_dwh1 = a0\n",
        "  dcost_dwh1 = np.dot(dzh1_dwh1.T,dah1_dzh1 *dcost_dah1)\n",
        "  dcost_dbh1 = dcost_dah1 * dah1_dzh1\n",
        "  #print(dzh1_dwh1)\n",
        "\n",
        "  wh1 -= lr * dcost_dwh1\n",
        "  bh1 -= lr * dcost_dbh1.sum(axis=0)\n",
        "\n",
        "  wh2 -= lr * dcost_dwh2\n",
        "  bh2 -= lr * dcost_dbh2.sum(axis=0)\n",
        "\n",
        "  wo -= lr * dcost_dwo\n",
        "  bo -= lr * dcost_dbo.sum(axis=0)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "        loss = np.sum(-y * np.log(ao))\n",
        "        print('Loss function value: ', loss)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss function value:  2.4440654471655012\n",
            "Loss function value:  2.1428071637286563\n",
            "Loss function value:  2.727416201260738\n",
            "Loss function value:  2.0845699011286096\n",
            "Loss function value:  2.4162781719019444\n",
            "Loss function value:  1.8436296251306923\n",
            "Loss function value:  2.315761913421953\n",
            "Loss function value:  2.341440733311132\n",
            "Loss function value:  2.7659789095345335\n",
            "Loss function value:  2.29788267741841\n",
            "Loss function value:  3.375219706394253\n",
            "Loss function value:  2.9505918167412117\n",
            "Loss function value:  2.6500701885973053\n",
            "Loss function value:  2.7424702572316817\n",
            "Loss function value:  2.7432298513612974\n",
            "Loss function value:  2.163145345564577\n",
            "Loss function value:  2.522200385467925\n",
            "Loss function value:  1.9593662364752662\n",
            "Loss function value:  1.9687056793247348\n",
            "Loss function value:  1.3405813619569567\n",
            "Loss function value:  2.6937260478346294\n",
            "Loss function value:  2.1754762379118278\n",
            "Loss function value:  2.2774844380013723\n",
            "Loss function value:  2.2081647898387096\n",
            "Loss function value:  2.914464625071548\n",
            "Loss function value:  2.302778120044448\n",
            "Loss function value:  2.2701245117252085\n",
            "Loss function value:  2.214307354948144\n",
            "Loss function value:  2.680963163741909\n",
            "Loss function value:  2.519317345666877\n",
            "Loss function value:  2.9355845016043536\n",
            "Loss function value:  2.3131463148466413\n",
            "Loss function value:  2.663636363283652\n",
            "Loss function value:  2.2327669996105413\n",
            "Loss function value:  2.344317073117093\n",
            "Loss function value:  1.8928104517637674\n",
            "Loss function value:  2.6598250355066853\n",
            "Loss function value:  2.622248039679554\n",
            "Loss function value:  1.394338289861841\n",
            "Loss function value:  1.7824203297392218\n",
            "Loss function value:  1.869394324360458\n",
            "Loss function value:  2.1946755825925766\n",
            "Loss function value:  2.2175156664839926\n",
            "Loss function value:  2.7192027340389946\n",
            "Loss function value:  2.429900045443189\n",
            "Loss function value:  2.161703390674381\n",
            "Loss function value:  2.678091478172233\n",
            "Loss function value:  1.9232306646494584\n",
            "Loss function value:  2.6485954193649546\n",
            "Loss function value:  2.3527031580161344\n",
            "Loss function value:  2.0349884872276047\n",
            "Loss function value:  1.6590424947204363\n",
            "Loss function value:  2.932984458626778\n",
            "Loss function value:  2.957032166238048\n",
            "Loss function value:  3.0412871185195676\n",
            "Loss function value:  2.7675469008848044\n",
            "Loss function value:  3.1215857777937766\n",
            "Loss function value:  1.552183472405814\n",
            "Loss function value:  2.814092192516192\n",
            "Loss function value:  2.3507986176517592\n",
            "Loss function value:  2.0569194030326092\n",
            "Loss function value:  3.2868496039668567\n",
            "Loss function value:  2.583890013472529\n",
            "Loss function value:  2.4475982755165346\n",
            "Loss function value:  1.5818940382496378\n",
            "Loss function value:  2.380647098821719\n",
            "Loss function value:  2.232806567719062\n",
            "Loss function value:  2.88261953690568\n",
            "Loss function value:  2.1763802631751363\n",
            "Loss function value:  2.7862361625014476\n",
            "Loss function value:  1.7918011100799816\n",
            "Loss function value:  2.4658383498047987\n",
            "Loss function value:  2.6909172190241044\n",
            "Loss function value:  1.8605749972498753\n",
            "Loss function value:  1.6974390839538718\n",
            "Loss function value:  2.6405302751939765\n",
            "Loss function value:  2.8597363400642677\n",
            "Loss function value:  2.392481884692473\n",
            "Loss function value:  2.4438537246843217\n",
            "Loss function value:  2.146428504117476\n",
            "Loss function value:  2.096955156716018\n",
            "Loss function value:  2.321368030103368\n",
            "Loss function value:  2.0708677608593664\n",
            "Loss function value:  2.6546622289785584\n",
            "Loss function value:  3.1554395868012284\n",
            "Loss function value:  1.615248910883918\n",
            "Loss function value:  2.387150840161803\n",
            "Loss function value:  3.042294732149555\n",
            "Loss function value:  2.786050869470267\n",
            "Loss function value:  2.15867074732339\n",
            "Loss function value:  3.081960608194135\n",
            "Loss function value:  2.6085091439986257\n",
            "Loss function value:  2.404424908543164\n",
            "Loss function value:  2.580920507161905\n",
            "Loss function value:  2.252942933373222\n",
            "Loss function value:  1.5184182327809281\n",
            "Loss function value:  2.302231197388604\n",
            "Loss function value:  2.1102739406678155\n",
            "Loss function value:  2.780354489286615\n",
            "Loss function value:  2.0868518258783992\n",
            "Loss function value:  2.211390177087856\n",
            "Loss function value:  3.363236168704882\n",
            "Loss function value:  2.753383852415112\n",
            "Loss function value:  2.677134815341935\n",
            "Loss function value:  2.1946188823299058\n",
            "Loss function value:  2.646679598283277\n",
            "Loss function value:  2.1428530130419223\n",
            "Loss function value:  3.3481094584557636\n",
            "Loss function value:  2.1928689909944885\n",
            "Loss function value:  2.5927065774188285\n",
            "Loss function value:  2.617400224214084\n",
            "Loss function value:  2.282923070645159\n",
            "Loss function value:  2.6374971195049457\n",
            "Loss function value:  2.372200622384462\n",
            "Loss function value:  2.3477671845899653\n",
            "Loss function value:  2.015051311246433\n",
            "Loss function value:  2.9025617803321815\n",
            "Loss function value:  3.2994260459460723\n",
            "Loss function value:  1.6021868552502032\n",
            "Loss function value:  1.863521012148876\n",
            "Loss function value:  2.0564048532354633\n",
            "Loss function value:  3.1412470921907762\n",
            "Loss function value:  1.8177350997726864\n",
            "Loss function value:  2.7861975531396586\n",
            "Loss function value:  2.56337352252639\n",
            "Loss function value:  2.945334136014677\n",
            "Loss function value:  2.4749549088706555\n",
            "Loss function value:  1.9817792191833545\n",
            "Loss function value:  1.6482151706363874\n",
            "Loss function value:  3.1846500143566407\n",
            "Loss function value:  3.1544688517250283\n",
            "Loss function value:  3.3152858795559736\n",
            "Loss function value:  1.8235810813749598\n",
            "Loss function value:  3.156020612382632\n",
            "Loss function value:  2.2541746767269135\n",
            "Loss function value:  2.5024679493840436\n",
            "Loss function value:  2.232609439661788\n",
            "Loss function value:  2.0307522749165052\n",
            "Loss function value:  2.5799750652214004\n",
            "Loss function value:  2.5285081630014634\n",
            "Loss function value:  2.465984327389073\n",
            "Loss function value:  2.0635333499455375\n",
            "Loss function value:  2.4312203646188615\n",
            "Loss function value:  2.4165595650376464\n",
            "Loss function value:  2.7417970261707376\n",
            "Loss function value:  2.726650744111347\n",
            "Loss function value:  2.3974100187708727\n",
            "Loss function value:  2.3641535978389383\n",
            "Loss function value:  3.146191534508375\n",
            "Loss function value:  1.839301761678385\n",
            "Loss function value:  3.047198984448819\n",
            "Loss function value:  3.0494079057080135\n",
            "Loss function value:  1.9228892004531424\n",
            "Loss function value:  2.413021593526307\n",
            "Loss function value:  1.7253849943238957\n",
            "Loss function value:  2.2999794180877715\n",
            "Loss function value:  2.3960096460682125\n",
            "Loss function value:  2.7021227788441404\n",
            "Loss function value:  1.9054106295826825\n",
            "Loss function value:  2.8257242023565015\n",
            "Loss function value:  2.2623966642515865\n",
            "Loss function value:  2.7516630070706456\n",
            "Loss function value:  2.27098616816004\n",
            "Loss function value:  2.370764915939017\n",
            "Loss function value:  2.790752981835717\n",
            "Loss function value:  2.642559002697833\n",
            "Loss function value:  2.412682433343514\n",
            "Loss function value:  2.9182357156042786\n",
            "Loss function value:  2.1239465620535074\n",
            "Loss function value:  3.064262360420101\n",
            "Loss function value:  1.3008890991187227\n",
            "Loss function value:  1.7560371202206289\n",
            "Loss function value:  2.9493933673933905\n",
            "Loss function value:  3.0382591705806967\n",
            "Loss function value:  1.644784830667646\n",
            "Loss function value:  2.3834379185691534\n",
            "Loss function value:  1.999761055316642\n",
            "Loss function value:  2.8585586246675305\n",
            "Loss function value:  1.5093217938406358\n",
            "Loss function value:  1.3172385732040492\n",
            "Loss function value:  2.884356474371373\n",
            "Loss function value:  2.571933521294618\n",
            "Loss function value:  2.82595361375309\n",
            "Loss function value:  2.812108903049516\n",
            "Loss function value:  2.542783764000889\n",
            "Loss function value:  3.0426048122889684\n",
            "Loss function value:  2.1329465786125974\n",
            "Loss function value:  2.2364167437595612\n",
            "Loss function value:  2.5023759637123\n",
            "Loss function value:  1.884815623961357\n",
            "Loss function value:  1.7047211372693938\n",
            "Loss function value:  2.7313002937478963\n",
            "Loss function value:  2.5752815675895078\n",
            "Loss function value:  1.6842855289678775\n",
            "Loss function value:  1.707537245338308\n",
            "Loss function value:  1.6044322204348402\n",
            "Loss function value:  2.06785486380787\n",
            "Loss function value:  2.334618798011454\n",
            "Loss function value:  2.944312776307236\n",
            "Loss function value:  1.94735562482708\n",
            "Loss function value:  1.4069218062818185\n",
            "Loss function value:  2.112876702049037\n",
            "Loss function value:  2.7345261768965274\n",
            "Loss function value:  2.149503708507879\n",
            "Loss function value:  2.4246707968006334\n",
            "Loss function value:  1.9931822171280609\n",
            "Loss function value:  3.011748585795847\n",
            "Loss function value:  1.4705942357448991\n",
            "Loss function value:  2.931740371178324\n",
            "Loss function value:  2.9221187389767898\n",
            "Loss function value:  2.3622125299318864\n",
            "Loss function value:  2.3806716568252906\n",
            "Loss function value:  2.7653019419509515\n",
            "Loss function value:  1.6667319920039458\n",
            "Loss function value:  2.59066773727971\n",
            "Loss function value:  2.4853192743625403\n",
            "Loss function value:  2.732416290197957\n",
            "Loss function value:  2.6286613343344003\n",
            "Loss function value:  2.0682701276175375\n",
            "Loss function value:  1.9158712124429578\n",
            "Loss function value:  2.4751071059677825\n",
            "Loss function value:  2.9095784134576483\n",
            "Loss function value:  1.7467075775578738\n",
            "Loss function value:  2.270644182419308\n",
            "Loss function value:  1.5947597569070437\n",
            "Loss function value:  2.725176641342208\n",
            "Loss function value:  2.6423842916064735\n",
            "Loss function value:  2.694783861177788\n",
            "Loss function value:  2.3094955188566018\n",
            "Loss function value:  1.938892971757486\n",
            "Loss function value:  1.6332478700987134\n",
            "Loss function value:  2.7874000139993518\n",
            "Loss function value:  2.2447408925135037\n",
            "Loss function value:  1.6265997702150594\n",
            "Loss function value:  2.246597048827305\n",
            "Loss function value:  3.0106780679114924\n",
            "Loss function value:  2.60521533095612\n",
            "Loss function value:  2.546903842616571\n",
            "Loss function value:  2.2891517304815836\n",
            "Loss function value:  3.0559267065569102\n",
            "Loss function value:  1.8178887626100346\n",
            "Loss function value:  2.741428252379856\n",
            "Loss function value:  2.09051201996937\n",
            "Loss function value:  2.908359503215492\n",
            "Loss function value:  2.149126767858614\n",
            "Loss function value:  3.1958195169646264\n",
            "Loss function value:  2.674616359792493\n",
            "Loss function value:  3.243507883565554\n",
            "Loss function value:  1.986373557344485\n",
            "Loss function value:  1.9351979735511453\n",
            "Loss function value:  2.617068086637391\n",
            "Loss function value:  2.3257348882024824\n",
            "Loss function value:  3.029694942780816\n",
            "Loss function value:  2.9825903223536874\n",
            "Loss function value:  2.875471900362409\n",
            "Loss function value:  2.63236193140543\n",
            "Loss function value:  2.4391005346903016\n",
            "Loss function value:  2.670829444600216\n",
            "Loss function value:  2.2718573318033126\n",
            "Loss function value:  2.213698597633554\n",
            "Loss function value:  2.5255862456710845\n",
            "Loss function value:  2.7885330182206087\n",
            "Loss function value:  2.886276677655263\n",
            "Loss function value:  2.056436119182192\n",
            "Loss function value:  2.728653269810532\n",
            "Loss function value:  2.7811489237885243\n",
            "Loss function value:  2.811582131268608\n",
            "Loss function value:  2.537572162302734\n",
            "Loss function value:  2.5700791917256973\n",
            "Loss function value:  2.888851515349879\n",
            "Loss function value:  2.05886405460203\n",
            "Loss function value:  3.082606332331921\n",
            "Loss function value:  2.630944738064221\n",
            "Loss function value:  1.7620645781566797\n",
            "Loss function value:  1.8531674105330584\n",
            "Loss function value:  2.7465247506518153\n",
            "Loss function value:  2.3541545365013046\n",
            "Loss function value:  2.386478464030017\n",
            "Loss function value:  2.345678910680461\n",
            "Loss function value:  2.549321683527461\n",
            "Loss function value:  2.5994312835833613\n",
            "Loss function value:  2.9492117190784235\n",
            "Loss function value:  1.7449051319163082\n",
            "Loss function value:  2.3256444791793576\n",
            "Loss function value:  2.1236980887992143\n",
            "Loss function value:  2.010108092895605\n",
            "Loss function value:  3.204189681862908\n",
            "Loss function value:  2.3994461490544725\n",
            "Loss function value:  2.6518006069596503\n",
            "Loss function value:  2.4489771014402875\n",
            "Loss function value:  2.9036270688593193\n",
            "Loss function value:  2.6123791410842454\n",
            "Loss function value:  1.9062515692360413\n",
            "Loss function value:  1.886453593780029\n",
            "Loss function value:  3.2670757086015656\n",
            "Loss function value:  2.5645493238257524\n",
            "Loss function value:  2.689416602598069\n",
            "Loss function value:  2.678280814867967\n",
            "Loss function value:  2.7279120188765162\n",
            "Loss function value:  2.670222358433956\n",
            "Loss function value:  2.3557672646255194\n",
            "Loss function value:  1.9370477907269514\n",
            "Loss function value:  2.804138407046506\n",
            "Loss function value:  2.5556809455854648\n",
            "Loss function value:  1.7373358676448152\n",
            "Loss function value:  2.357919795723679\n",
            "Loss function value:  2.8839021285582063\n",
            "Loss function value:  2.469115484530089\n",
            "Loss function value:  2.520516285689167\n",
            "Loss function value:  1.864754683372775\n",
            "Loss function value:  2.016337112868001\n",
            "Loss function value:  1.909837591685241\n",
            "Loss function value:  2.2258083385992125\n",
            "Loss function value:  2.032205897549092\n",
            "Loss function value:  3.188610197056305\n",
            "Loss function value:  3.280134666912561\n",
            "Loss function value:  2.7325785105225515\n",
            "Loss function value:  3.0758275277658185\n",
            "Loss function value:  2.871487978155087\n",
            "Loss function value:  2.2358349428953703\n",
            "Loss function value:  2.115417386930927\n",
            "Loss function value:  2.097041915437139\n",
            "Loss function value:  2.369983240051039\n",
            "Loss function value:  2.5474233944491065\n",
            "Loss function value:  1.7256412535507963\n",
            "Loss function value:  1.6158401970003202\n",
            "Loss function value:  2.636594488474482\n",
            "Loss function value:  1.759132610752901\n",
            "Loss function value:  2.166901080448887\n",
            "Loss function value:  2.3232231143499877\n",
            "Loss function value:  3.2688396775353152\n",
            "Loss function value:  1.879955989643654\n",
            "Loss function value:  1.91149110607463\n",
            "Loss function value:  2.1322333892342704\n",
            "Loss function value:  2.5448857425801146\n",
            "Loss function value:  2.5252965767303097\n",
            "Loss function value:  1.9652574033757753\n",
            "Loss function value:  2.1704986271999984\n",
            "Loss function value:  1.8118085492027622\n",
            "Loss function value:  2.5716260188946682\n",
            "Loss function value:  2.2494574693110345\n",
            "Loss function value:  2.0222877994209005\n",
            "Loss function value:  3.2101599167987893\n",
            "Loss function value:  1.8554494058404996\n",
            "Loss function value:  1.9530840196353014\n",
            "Loss function value:  2.314393757190742\n",
            "Loss function value:  2.71624482453759\n",
            "Loss function value:  3.344142197985224\n",
            "Loss function value:  2.7199070722014516\n",
            "Loss function value:  2.77203384387565\n",
            "Loss function value:  3.4531714472373216\n",
            "Loss function value:  2.1847076031986754\n",
            "Loss function value:  3.3829036315732024\n",
            "Loss function value:  2.571038243819489\n",
            "Loss function value:  2.7116808546305746\n",
            "Loss function value:  2.6930047711632032\n",
            "Loss function value:  1.90453226479141\n",
            "Loss function value:  2.6702387139430206\n",
            "Loss function value:  2.314226792014192\n",
            "Loss function value:  2.361282213614487\n",
            "Loss function value:  2.630826849774217\n",
            "Loss function value:  2.4317567878184505\n",
            "Loss function value:  2.194881507628602\n",
            "Loss function value:  2.3643838533304167\n",
            "Loss function value:  2.405907005856987\n",
            "Loss function value:  2.406929847034301\n",
            "Loss function value:  2.1879900108895636\n",
            "Loss function value:  2.5031615871838113\n",
            "Loss function value:  1.5100167548227514\n",
            "Loss function value:  1.8506378416694458\n",
            "Loss function value:  3.1741193690015104\n",
            "Loss function value:  2.8999308262508787\n",
            "Loss function value:  1.892976133375408\n",
            "Loss function value:  2.394973689187665\n",
            "Loss function value:  2.5580180146150298\n",
            "Loss function value:  2.282261275350682\n",
            "Loss function value:  2.5925768625843895\n",
            "Loss function value:  2.5722687297195055\n",
            "Loss function value:  2.6543649910990434\n",
            "Loss function value:  1.9185352687869022\n",
            "Loss function value:  2.5926126630438286\n",
            "Loss function value:  2.709109715837158\n",
            "Loss function value:  2.086895606250546\n",
            "Loss function value:  2.4213031208607476\n",
            "Loss function value:  2.701047850102996\n",
            "Loss function value:  2.766598262776155\n",
            "Loss function value:  2.5103449384268455\n",
            "Loss function value:  2.1905830295738915\n",
            "Loss function value:  2.0435415852937826\n",
            "Loss function value:  1.9095503203500188\n",
            "Loss function value:  1.6799067397347665\n",
            "Loss function value:  2.634224041605428\n",
            "Loss function value:  3.411837544467665\n",
            "Loss function value:  2.229943137261121\n",
            "Loss function value:  2.2951226993574783\n",
            "Loss function value:  1.8933508852720555\n",
            "Loss function value:  1.896490884593434\n",
            "Loss function value:  2.679453503610003\n",
            "Loss function value:  2.5496744845030888\n",
            "Loss function value:  2.2534665546253088\n",
            "Loss function value:  2.9245469608070778\n",
            "Loss function value:  2.3644814428287915\n",
            "Loss function value:  3.062254687719331\n",
            "Loss function value:  2.6767428096037396\n",
            "Loss function value:  2.425749533021214\n",
            "Loss function value:  2.206234021258808\n",
            "Loss function value:  1.9433967581291973\n",
            "Loss function value:  1.6690230518714937\n",
            "Loss function value:  2.816552482579171\n",
            "Loss function value:  1.8278426727142305\n",
            "Loss function value:  2.7033396932390743\n",
            "Loss function value:  2.6071139474000216\n",
            "Loss function value:  2.5056691885980484\n",
            "Loss function value:  3.1690136303652205\n",
            "Loss function value:  1.8428890646974565\n",
            "Loss function value:  2.7676754751319748\n",
            "Loss function value:  2.0196272544559113\n",
            "Loss function value:  2.68776758596771\n",
            "Loss function value:  1.5741685394973814\n",
            "Loss function value:  2.2467577815728506\n",
            "Loss function value:  2.6385084785297277\n",
            "Loss function value:  2.706506778858797\n",
            "Loss function value:  1.8841740342524729\n",
            "Loss function value:  2.618672376400686\n",
            "Loss function value:  2.6214002498037035\n",
            "Loss function value:  1.6934601239214295\n",
            "Loss function value:  2.7915821353724075\n",
            "Loss function value:  2.467086644371346\n",
            "Loss function value:  2.1941840903211998\n",
            "Loss function value:  3.4946335890664644\n",
            "Loss function value:  2.2061769584587814\n",
            "Loss function value:  2.5950071624512527\n",
            "Loss function value:  1.992752250039601\n",
            "Loss function value:  2.176647507627685\n",
            "Loss function value:  2.525235268340559\n",
            "Loss function value:  2.227750709454639\n",
            "Loss function value:  2.9049978091752537\n",
            "Loss function value:  2.8645996913650214\n",
            "Loss function value:  2.8263432283616816\n",
            "Loss function value:  2.934280593349147\n",
            "Loss function value:  2.9306382665098605\n",
            "Loss function value:  1.904572879474962\n",
            "Loss function value:  2.2334452551378536\n",
            "Loss function value:  2.289642667798066\n",
            "Loss function value:  2.746714628215951\n",
            "Loss function value:  2.5341246119418708\n",
            "Loss function value:  2.1413026877457852\n",
            "Loss function value:  2.376885749960661\n",
            "Loss function value:  2.450428966859135\n",
            "Loss function value:  2.950310136453719\n",
            "Loss function value:  2.157291034357369\n",
            "Loss function value:  1.929738292728515\n",
            "Loss function value:  2.7219322056214037\n",
            "Loss function value:  2.004332941855949\n",
            "Loss function value:  2.3469458255264577\n",
            "Loss function value:  2.344644260608103\n",
            "Loss function value:  2.491512902477086\n",
            "Loss function value:  2.970333834917791\n",
            "Loss function value:  2.8920617174766705\n",
            "Loss function value:  2.8792326631829313\n",
            "Loss function value:  2.2705232428624744\n",
            "Loss function value:  2.413347748320925\n",
            "Loss function value:  2.4296990104292173\n",
            "Loss function value:  2.336022209059947\n",
            "Loss function value:  2.0951119718292777\n",
            "Loss function value:  1.8240096793071483\n",
            "Loss function value:  2.712260828032862\n",
            "Loss function value:  2.1455767510359967\n",
            "Loss function value:  2.389985321652264\n",
            "Loss function value:  1.898233480173474\n",
            "Loss function value:  1.55248295635873\n",
            "Loss function value:  2.2391499136201456\n",
            "Loss function value:  2.854977845139021\n",
            "Loss function value:  2.792192301489844\n",
            "Loss function value:  2.2277533296005236\n",
            "Loss function value:  2.888680648099607\n",
            "Loss function value:  2.4972668796331305\n",
            "Loss function value:  2.6012607044131624\n",
            "Loss function value:  1.9857631957079598\n",
            "Loss function value:  2.4884322620958788\n",
            "Loss function value:  3.015092403681428\n",
            "Loss function value:  2.325021855544817\n",
            "Loss function value:  3.0086220563709154\n",
            "Loss function value:  1.9749401414374574\n",
            "Loss function value:  2.770981586431152\n",
            "Loss function value:  2.7162454133220697\n",
            "Loss function value:  1.8188027362780184\n",
            "Loss function value:  2.5328413438655617\n",
            "Loss function value:  2.8299605804445616\n",
            "Loss function value:  2.644849478062451\n",
            "Loss function value:  2.875831670771985\n",
            "Loss function value:  2.428506125473487\n",
            "Loss function value:  2.3094729277158863\n",
            "Loss function value:  2.116081859879765\n",
            "Loss function value:  3.117571146337461\n",
            "Loss function value:  1.9550328309419984\n",
            "Loss function value:  1.5000625348931966\n",
            "Loss function value:  1.9991983980708397\n",
            "Loss function value:  3.1618737843068923\n",
            "Loss function value:  2.7216411720458082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3gMU3wmSWKx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}