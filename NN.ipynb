{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2E3LpKpMxYK9bh3F6hTJZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksk94966/XNN_Math/blob/master/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct1oP-ACslzA"
      },
      "source": [
        "import os.path\n",
        "import urllib.request\n",
        "import gzip\n",
        "import math\n",
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data\n",
        "DATA_NUM_TRAIN         = 60000\n",
        "DATA_NUM_TEST          = 10000\n",
        "DATA_CHANNELS          = 1\n",
        "DATA_ROWS              = 28\n",
        "DATA_COLS              = 28\n",
        "DATA_CLASSES           = 10\n",
        "DATA_URL_TRAIN_DATA    = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "DATA_URL_TRAIN_LABELS  = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "DATA_URL_TEST_DATA     = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "DATA_URL_TEST_LABELS   = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "DATA_FILE_TRAIN_DATA   = 'train_data.gz'\n",
        "DATA_FILE_TRAIN_LABELS = 'train_labels.gz'\n",
        "DATA_FILE_TEST_DATA    = 'test_data.gz'\n",
        "DATA_FILE_TEST_LABELS  = 'test_labels.gz'\n",
        "\n",
        "# display\n",
        "DISPLAY_ROWS   = 8\n",
        "DISPLAY_COLS   = 4\n",
        "DISPLAY_COL_IN = 10\n",
        "DISPLAY_ROW_IN = 25\n",
        "DISPLAY_NUM    = DISPLAY_ROWS*DISPLAY_COLS\n",
        "\n",
        "# download\n",
        "if (os.path.exists(DATA_FILE_TRAIN_DATA)   == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_DATA,   DATA_FILE_TRAIN_DATA)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_LABELS) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_LABELS, DATA_FILE_TRAIN_LABELS)\n",
        "if (os.path.exists(DATA_FILE_TEST_DATA)    == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_DATA,    DATA_FILE_TEST_DATA)\n",
        "if (os.path.exists(DATA_FILE_TEST_LABELS)  == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_LABELS,  DATA_FILE_TEST_LABELS)\n",
        "\n",
        "# training data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_train_data   = gzip.open(DATA_FILE_TRAIN_DATA, 'r')\n",
        "file_train_data.read(16)\n",
        "buffer_train_data = file_train_data.read(DATA_NUM_TRAIN*DATA_ROWS*DATA_COLS)\n",
        "train_data        = np.frombuffer(buffer_train_data, dtype=np.uint8).astype(np.float32)\n",
        "train_data        = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# training labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_train_labels   = gzip.open(DATA_FILE_TRAIN_LABELS, 'r')\n",
        "file_train_labels.read(8)\n",
        "buffer_train_labels = file_train_labels.read(DATA_NUM_TRAIN)\n",
        "train_labels        = np.frombuffer(buffer_train_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# testing data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_test_data   = gzip.open(DATA_FILE_TEST_DATA, 'r')\n",
        "file_test_data.read(16)\n",
        "buffer_test_data = file_test_data.read(DATA_NUM_TEST*DATA_ROWS*DATA_COLS)\n",
        "test_data        = np.frombuffer(buffer_test_data, dtype=np.uint8).astype(np.float32)\n",
        "test_data        = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# testing labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_test_labels   = gzip.open(DATA_FILE_TEST_LABELS, 'r')\n",
        "file_test_labels.read(8)\n",
        "buffer_test_labels = file_test_labels.read(DATA_NUM_TEST)\n",
        "test_labels        = np.frombuffer(buffer_test_labels, dtype=np.uint8).astype(np.int32)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygX7HRKtP4A",
        "outputId": "6eb1f62d-333a-4f9d-9fc6-969b99279ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Printing dimensions\n",
        "print(train_data.shape)   # (60000, 1, 28, 28)\n",
        "print(train_labels.shape) # (60000,)\n",
        "print(test_data.shape)    # (10000, 1, 28, 28)\n",
        "print(test_labels.shape)  # (10000,)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1, 28, 28)\n",
            "(60000,)\n",
            "(10000, 1, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEvk6X1VW63S"
      },
      "source": [
        "#hidden Layer1\n",
        "wh1 = np.random.rand(784,1000)/np.sqrt(784)\n",
        "bh1 = np.random.rand(1,1000)\n",
        "\n",
        "#hidden Layer2\n",
        "wh2 = np.random.rand(1000,100)/np.sqrt(1000)\n",
        "bh2 = np.random.rand(1,100)\n",
        "\n",
        "#Output Layer\n",
        "wo = np.random.rand(100,10)/np.sqrt(100)\n",
        "bo = np.random.rand(1,10)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fzy5El4MfL"
      },
      "source": [
        "def multi1(v):\n",
        "  return np.dot(v,wh1)\n",
        "\n",
        "def multi2(v):\n",
        "  return np.dot(v,wh2)\n",
        "\n",
        "def multi3(v):\n",
        "  return np.dot(v,wo)\n",
        "\n",
        "def ReLU(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x /np.sum(e_x)\n",
        "\n",
        "def getLabelMatrix(i):\n",
        "  lab = np.zeros((1,10))\n",
        "  lab[0][i] = 1\n",
        "  return lab"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQrp7MZ84Ssa",
        "outputId": "52f95c60-4cca-4153-a814-194ce37f4bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "import timeit\n",
        "\n",
        "epoch_accuracy = dict()\n",
        "accuracy_label_encountered = dict()\n",
        "accuracy_label_correct = dict()\n",
        "\n",
        "for i in range(10):\n",
        "  accuracy_label_encountered[i] = 0       \n",
        "\n",
        "for i in range(10):\n",
        "  accuracy_label_correct[i] = 0\n",
        "\n",
        "lr = 0.001                    # Learning Rate\n",
        "\n",
        "train_data =  (train_data/255).astype('float32')\n",
        "test_data =  (test_data/255).astype('float32')\n",
        "\n",
        "\n",
        "#testing forward pass function\n",
        "\n",
        "def testingNN(testdata,testlabels):\n",
        "  count = 0;\n",
        "  total = 0; \n",
        "#Forward Pass\n",
        "  for sample in range(2000):\n",
        "    a0 = testdata[sample]                                                                    #division by 255\n",
        "    a0 = a0.reshape(1,784)                                                                 #Reshaping ---> Vectorization\n",
        "    #print(bh1)\n",
        "\n",
        "    #Passing the sample through first hidden layer\n",
        "    zh1 = np.add(multi1(a0) ,bh1)                                                                    #Creating Zh1 which is addtion of weights and bias\n",
        "    ah1 = ReLU(zh1)                                                                                            #Generated hiddenlayer1 Activations\n",
        "    # print(ah1)\n",
        "\n",
        "    #passing the h1 sample through second hiddden layer\n",
        "    zh2 = np.add(multi2(ah1), bh2)                                                                   #Creating Zh2 which is addtion of weights and bias\n",
        "    ah2 = ReLU(zh2)                                                                                             #Generated hiddenlayer2 Activations \n",
        "    \n",
        "\n",
        "    #passing the h2 sample through third hiddden layer\n",
        "    zo = np.add(multi3(ah2) ,bo)                                                                        #Creating Zo which is addtion of weights and bias\n",
        "    ao = softmax(zo)                                                                                             #Generated output Activations\n",
        "    #print(ao)\n",
        "\n",
        "    pred = np.argmax(ao)\n",
        "\n",
        "    #print(pred)\n",
        "\n",
        "    y = getLabelMatrix(testlabels[sample])                          #desired output label\n",
        "\n",
        "    accuracy_label_encountered[testlabels[sample]] += 1\n",
        "    #print(y)\n",
        "\n",
        "    if(y[0][pred]):\n",
        "      count += 1\n",
        "      accuracy_label_correct[pred] += 1 \n",
        "    \n",
        "    total += 1\n",
        "\n",
        "  #print((count/total)*100)\n",
        "\n",
        "  return (count/total)*100\n",
        "\n",
        "count = 0;\n",
        "total = 0; \n",
        "#Training epochs \n",
        "for epoch in range(2):\n",
        "  epoch_number = epoch + 1\n",
        "  start = timeit.timeit()\n",
        "  total_LossPerEpoch = 0\n",
        "  #Training Forward Pass\n",
        "  for sample in range(40000):\n",
        "    a0 = np.copy(train_data[sample])                                               \n",
        "    a0 = a0.reshape(1,784)                                                                 #Reshaping ---> Vectorization\n",
        "    # print(bh1)\n",
        "\n",
        "    #Passing the sample through first hidden layer\n",
        "    zh1 = np.add(multi1(a0) ,bh1)                                                                    #Creating Zh1 which is addtion of weights and bias\n",
        "    ah1 = ReLU(zh1)                                                                                            #Generated hiddenlayer1 Activations\n",
        "    # print(ah1)\n",
        "\n",
        "    #passing the h1 sample through second hiddden layer\n",
        "    zh2 = np.add(multi2(ah1), bh2)                                                                   #Creating Zh2 which is addtion of weights and bias\n",
        "    ah2 = ReLU(zh2)                                                                                             #Generated hiddenlayer2 Activations \n",
        "    \n",
        "    #passing the sample to get output\n",
        "    zo = np.add(multi3(ah2) ,bo)                                                                        #Creating Zo which is addtion of weights and bias\n",
        "    ao = softmax(zo)                                                                                             #Generated output Activations\n",
        "    #print(ao)\n",
        "\n",
        "    y = getLabelMatrix(train_labels[sample])                                              #desired output label\n",
        "\n",
        "    #Here we are using entropy function as loss function\n",
        "    #BackPropagation----------------------------------------------------------\n",
        "\n",
        "    #phase 1              ---> for the output layer\n",
        "    dcost_dzo = ao - y                                                                             #(1,10)\n",
        "    dzo_dwo = ah2.transpose()                                                            #(1,100)   --> we have to transpose this one\n",
        "    dcost_dwo = np.dot( dzo_dwo,dcost_dzo)                                 #derivate of cost w.r.t output weights      #(100,10)\n",
        "    dcost_dbo = dcost_dzo                                                                   #derivative of cost w.r.t bias                      #(1,10)\n",
        "\n",
        "    #phase 2              ---> for the hidden layer 2 \n",
        "    dzo_dah2 = wo\n",
        "    dcost_dah2 = np.dot(dcost_dzo , dzo_dah2.transpose())\n",
        "    dah2_dzh2 = reluDerivative(zh2)\n",
        "    dzh2_dwh2 = ah1\n",
        "    dcost_dwh2 = np.dot(dzh2_dwh2.T,dah2_dzh2*dcost_dah2)\n",
        "    dcost_dbh2 = dcost_dah2 * dah2_dzh2\n",
        "    #print(dcost_dwh2)\n",
        "\n",
        "    #phase 3   ---- > for hidden layer 1\n",
        "    dzh2_dah1 = wh2\n",
        "    dcost_dzh2 = dcost_dah2 * dah2_dzh2\n",
        "    dcost_dah1 = np.dot(dcost_dzh2,dzh2_dah1.transpose()) \n",
        "    dah1_dzh1 = reluDerivative(zh1)\n",
        "    dzh1_dwh1 = a0\n",
        "    dcost_dwh1 = np.dot(dzh1_dwh1.T,dah1_dzh1 *dcost_dah1)\n",
        "    dcost_dbh1 = dcost_dah1 * dah1_dzh1\n",
        "    #print(dzh1_dwh1)\n",
        "\n",
        "    wh1 -= lr * dcost_dwh1\n",
        "    bh1 -= lr * dcost_dbh1.sum(axis=0)\n",
        "\n",
        "    wh2 -= lr * dcost_dwh2\n",
        "    bh2 -= lr * dcost_dbh2.sum(axis=0)\n",
        "\n",
        "    wo -= lr * dcost_dwo\n",
        "    bo -= lr * dcost_dbo.sum(axis=0)\n",
        "    \n",
        "    loss = np.sum(-y * np.log(ao))\n",
        "    total_LossPerEpoch += loss\n",
        "    #print('Loss function value: ', loss)\n",
        "  end = timeit.timeit()\n",
        "  time_elapsed = end - start\n",
        "  total_LossPerEpoch = total_LossPerEpoch/10000\n",
        "  test_accuracy_epoch =  testingNN(test_data,test_labels)\n",
        "  epoch_accuracy[epoch_number] = test_accuracy_epoch                  #plot for epoch vs accuracy\n",
        "\n",
        "\n",
        "accuracy_display = dict()\n",
        "for i in range(10):\n",
        "    if(accuracy_label_encountered[i]!=0):\n",
        "      accuracy_display[i]  = accuracy_label_correct[i]/accuracy_label_encountered[i]\n",
        "    else:\n",
        "      accuracy_display[i] = 0  \n",
        "\n",
        "print(accuracy_display)\n",
        "#final Value\n",
        "\n",
        "#plotting\n",
        "\n",
        "epoch_count = []\n",
        "epoch_testAccuracy = []\n",
        "for key in epoch_accuracy:\n",
        "  epoch_count.append(key)\n",
        "  epoch_testAccuracy.append(epoch_accuracy[key])\n",
        "\n",
        "plt.plot(epoch_count, epoch_testAccuracy, 'r--')\n",
        "plt.legend(['Epoch vs Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()      \n",
        "    "
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.6714285714285714, 1: 0.9594017094017094, 2: 0.4223744292237443, 3: 0.533816425120773, 4: 0.652073732718894, 5: 0.9608938547486033, 6: 0.7556179775280899, 7: 0.6024390243902439, 8: 0.5833333333333334, 9: 0.8273195876288659}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3gMU3wmSWKx"
      },
      "source": [
        "def testingNN(testdata,testlabels):\n",
        "  count = 0;\n",
        "  total = 0; \n",
        "#Forward Pass\n",
        "  for sample in range(5000):\n",
        "    a0 = testdata[sample]                                                                    #division by 255\n",
        "    a0 = a0.reshape(1,784)                                                                 #Reshaping ---> Vectorization\n",
        "    #print(bh1)\n",
        "\n",
        "    #Passing the sample through first hidden layer\n",
        "    zh1 = np.add(multi1(a0) ,bh1)                                                                    #Creating Zh1 which is addtion of weights and bias\n",
        "    ah1 = ReLU(zh1)                                                                                            #Generated hiddenlayer1 Activations\n",
        "    # print(ah1)\n",
        "\n",
        "    #passing the h1 sample through second hiddden layer\n",
        "    zh2 = np.add(multi2(ah1), bh2)                                                                   #Creating Zh2 which is addtion of weights and bias\n",
        "    ah2 = ReLU(zh2)                                                                                             #Generated hiddenlayer2 Activations \n",
        "    \n",
        "\n",
        "    #passing the h2 sample through third hiddden layer\n",
        "    zo = np.add(multi3(ah2) ,bo)                                                                        #Creating Zo which is addtion of weights and bias\n",
        "    ao = softmax(zo)                                                                                             #Generated output Activations\n",
        "    #print(ao)\n",
        "\n",
        "    pred = np.argmax(ao)\n",
        "\n",
        "    #print(pred)\n",
        "\n",
        "    y = getLabelMatrix(testlabels[sample])                          #desired output label\n",
        "\n",
        "    #print(y)\n",
        "\n",
        "    if(y[0][pred]):\n",
        "      count += 1\n",
        "    \n",
        "    total += 1\n",
        "\n",
        "  print((count/total)*100)\n",
        "\n",
        "  return (count/total)*100"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBXOa0ZE1XNP",
        "outputId": "004b06c4-391b-4177-ea8b-d0f09be3627a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(testingNN(test_data,test_labels))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88.32\n",
            "88.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giQy5abS5xJy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}