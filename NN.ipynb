{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6UuA6QU7Zq3frb555v3Uv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksk94966/XNN_Math/blob/master/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct1oP-ACslzA"
      },
      "source": [
        "import os.path\n",
        "import urllib.request\n",
        "import gzip\n",
        "import math\n",
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data\n",
        "DATA_NUM_TRAIN         = 60000\n",
        "DATA_NUM_TEST          = 10000\n",
        "DATA_CHANNELS          = 1\n",
        "DATA_ROWS              = 28\n",
        "DATA_COLS              = 28\n",
        "DATA_CLASSES           = 10\n",
        "DATA_URL_TRAIN_DATA    = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "DATA_URL_TRAIN_LABELS  = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "DATA_URL_TEST_DATA     = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "DATA_URL_TEST_LABELS   = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "DATA_FILE_TRAIN_DATA   = 'train_data.gz'\n",
        "DATA_FILE_TRAIN_LABELS = 'train_labels.gz'\n",
        "DATA_FILE_TEST_DATA    = 'test_data.gz'\n",
        "DATA_FILE_TEST_LABELS  = 'test_labels.gz'\n",
        "\n",
        "# display\n",
        "DISPLAY_ROWS   = 8\n",
        "DISPLAY_COLS   = 4\n",
        "DISPLAY_COL_IN = 10\n",
        "DISPLAY_ROW_IN = 25\n",
        "DISPLAY_NUM    = DISPLAY_ROWS*DISPLAY_COLS\n",
        "\n",
        "# download\n",
        "if (os.path.exists(DATA_FILE_TRAIN_DATA)   == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_DATA,   DATA_FILE_TRAIN_DATA)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_LABELS) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_LABELS, DATA_FILE_TRAIN_LABELS)\n",
        "if (os.path.exists(DATA_FILE_TEST_DATA)    == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_DATA,    DATA_FILE_TEST_DATA)\n",
        "if (os.path.exists(DATA_FILE_TEST_LABELS)  == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_LABELS,  DATA_FILE_TEST_LABELS)\n",
        "\n",
        "# training data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_train_data   = gzip.open(DATA_FILE_TRAIN_DATA, 'r')\n",
        "file_train_data.read(16)\n",
        "buffer_train_data = file_train_data.read(DATA_NUM_TRAIN*DATA_ROWS*DATA_COLS)\n",
        "train_data        = np.frombuffer(buffer_train_data, dtype=np.uint8).astype(np.float32)\n",
        "train_data        = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# training labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_train_labels   = gzip.open(DATA_FILE_TRAIN_LABELS, 'r')\n",
        "file_train_labels.read(8)\n",
        "buffer_train_labels = file_train_labels.read(DATA_NUM_TRAIN)\n",
        "train_labels        = np.frombuffer(buffer_train_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# testing data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_test_data   = gzip.open(DATA_FILE_TEST_DATA, 'r')\n",
        "file_test_data.read(16)\n",
        "buffer_test_data = file_test_data.read(DATA_NUM_TEST*DATA_ROWS*DATA_COLS)\n",
        "test_data        = np.frombuffer(buffer_test_data, dtype=np.uint8).astype(np.float32)\n",
        "test_data        = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# testing labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_test_labels   = gzip.open(DATA_FILE_TEST_LABELS, 'r')\n",
        "file_test_labels.read(8)\n",
        "buffer_test_labels = file_test_labels.read(DATA_NUM_TEST)\n",
        "test_labels        = np.frombuffer(buffer_test_labels, dtype=np.uint8).astype(np.int32)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hygX7HRKtP4A",
        "outputId": "74d24cef-5cc4-4e91-eae9-d29cdca9c49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Printing dimensions\n",
        "print(train_data.shape)   # (60000, 1, 28, 28)\n",
        "print(train_labels.shape) # (60000,)\n",
        "print(test_data.shape)    # (10000, 1, 28, 28)\n",
        "print(test_labels.shape)  # (10000,)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1, 28, 28)\n",
            "(60000,)\n",
            "(10000, 1, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEvk6X1VW63S"
      },
      "source": [
        "\n",
        "#hidden Layer1\n",
        "wh1 = np.random.rand(784,1000)/np.sqrt(784)\n",
        "bh1 = np.random.rand(1,1000)\n",
        "\n",
        "#hidden Layer2\n",
        "wh2 = np.random.rand(1000,100)/np.sqrt(1000)\n",
        "bh2 = np.random.rand(1,100)\n",
        "\n",
        "#Output Layer\n",
        "wo = np.random.rand(100,10)/np.sqrt(100)\n",
        "bo = np.random.rand(1,10)\n",
        "\n"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7fzy5El4MfL"
      },
      "source": [
        "def multi1(v):\n",
        "  return np.dot(v,wh1)\n",
        "\n",
        "def multi2(v):\n",
        "  return np.dot(v,wh2)\n",
        "\n",
        "def multi3(v):\n",
        "  return np.dot(v,wo)\n",
        "\n",
        "def ReLU(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def reluDerivative(x):\n",
        "  x[x<=0] = 0\n",
        "  x[x>0] = 1\n",
        "  return x\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x /np.sum(e_x)\n",
        "\n",
        "def getLabelMatrix(i):\n",
        "  lab = np.zeros((1,10))\n",
        "  lab[0][i] = 1\n",
        "  return lab"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQrp7MZ84Ssa",
        "outputId": "a26cd926-cf59-4572-ae3b-d8243603505a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "lr = 0.8                     # Learning Rate\n",
        "\n",
        "#Forward Pass\n",
        "for epoch in range(5000):\n",
        "  a0 = train_data[epoch]/255.0                                                      #division by 255\n",
        "  a0 = a0.reshape(1,784)                                                                 #Reshaping ---> Vectorization\n",
        "  #print(bh1)\n",
        "\n",
        "  #Passing the sample through first hidden layer\n",
        "  zh1 = np.add(multi1(a0) ,bh1)                                                                    #Creating Zh1 which is addtion of weights and bias\n",
        "  ah1 = ReLU(zh1)                                                                                            #Generated hiddenlayer1 Activations\n",
        "  # print(ah1)\n",
        "\n",
        "  #passing the h1 sample through second hiddden layer\n",
        "  zh2 = np.add(multi2(ah1), bh2)                                                                   #Creating Zh2 which is addtion of weights and bias\n",
        "  ah2 = ReLU(zh2)                                                                                #Generated hiddenlayer2 Activations \n",
        "  \n",
        "\n",
        "  #passing the h2 sample through third hiddden layer\n",
        "  zo = np.add(multi3(ah2) ,bo)                                                                        #Creating Zo which is addtion of weights and bias\n",
        "  ao = softmax(zo)                                                                                             #Generated output Activations\n",
        "  #print(ao)\n",
        "  \n",
        "  y = getLabelMatrix(train_labels[epoch])                          #desired output label\n",
        "  #Here we are using entropy function as loss function\n",
        "\n",
        "  #BackPropagation----------------------------------------------------------\n",
        "\n",
        "  #phase 1              ---> for the output layer\n",
        "  dcost_dzo = ao - y                                                                             #(1,10)\n",
        "  dzo_dwo = ah2.transpose()                                                            #(1,100)   --> we have to transpose this one\n",
        "  dcost_dwo = np.dot( dzo_dwo,dcost_dzo)                                 #derivate of cost w.r.t output weights      #(100,10)\n",
        "  dcost_dbo = dcost_dzo                                                                   #derivative of cost w.r.t bias                      #(1,10)\n",
        "\n",
        "  #phase 2              ---> for the hidden layer 2 \n",
        "  dzo_dah2 = wo\n",
        "  dcost_dah2 = np.dot(dcost_dzo , dzo_dah2.transpose())\n",
        "  dah2_dzh2 = reluDerivative(zh2)\n",
        "  dzh2_dwh2 = ah1\n",
        "  dcost_dwh2 = np.dot(dzh2_dwh2.T,dah2_dzh2*dcost_dah2)\n",
        "  dcost_dbh2 = dcost_dah2 * dah2_dzh2\n",
        "  #print(dcost_dwh2)\n",
        "\n",
        "  #phase 3   ---- > for hidden layer 1\n",
        "  dzh2_dah1 = wh2\n",
        "  dcost_dzh2 = dcost_dah2 * dah2_dzh2\n",
        "  dcost_dah1 = np.dot(dcost_dzh2,dzh2_dah1.transpose()) \n",
        "  dah1_dzh1 = reluDerivative(zh1)\n",
        "  dzh1_dwh1 = a0\n",
        "  dcost_dwh1 = np.dot(dzh1_dwh1.T,dah1_dzh1 *dcost_dah1)\n",
        "  dcost_dbh1 = dcost_dah1 * dah1_dzh1\n",
        "  #print(dzh1_dwh1)\n",
        "\n",
        "  wh1 -= lr * dcost_dwh1\n",
        "  bh1 -= lr * dcost_dbh1.sum(axis=0)\n",
        "\n",
        "  wh2 -= lr * dcost_dwh2\n",
        "  bh2 -= lr * dcost_dbh2.sum(axis=0)\n",
        "\n",
        "  wo -= lr * dcost_dwo\n",
        "  bo -= lr * dcost_dbo.sum(axis=0)\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "        loss = np.sum(-y * np.log(ao))\n",
        "        print('Loss function value: ', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss function value:  21.34861237812724\n",
            "Loss function value:  2.21086376149668\n",
            "Loss function value:  2.572770988527843\n",
            "Loss function value:  2.1440005565311218\n",
            "Loss function value:  2.748102366128462\n",
            "Loss function value:  1.6874728630314917\n",
            "Loss function value:  2.104143472270003\n",
            "Loss function value:  2.3742178051756766\n",
            "Loss function value:  3.1148492448969187\n",
            "Loss function value:  2.3372844506971333\n",
            "Loss function value:  3.6300763292383373\n",
            "Loss function value:  3.1794983784686726\n",
            "Loss function value:  2.5608923606772898\n",
            "Loss function value:  2.9376237953597215\n",
            "Loss function value:  3.0042314463549196\n",
            "Loss function value:  2.263379776036546\n",
            "Loss function value:  2.644572353816717\n",
            "Loss function value:  1.8011396972897271\n",
            "Loss function value:  1.7814371870738566\n",
            "Loss function value:  1.04035118010288\n",
            "Loss function value:  2.859567229009355\n",
            "Loss function value:  1.860214131526063\n",
            "Loss function value:  2.40610536877636\n",
            "Loss function value:  2.2861101251282174\n",
            "Loss function value:  3.0600498163616776\n",
            "Loss function value:  2.435706471580779\n",
            "Loss function value:  2.448340697752309\n",
            "Loss function value:  2.1573858345704613\n",
            "Loss function value:  2.7988819693341527\n",
            "Loss function value:  2.7134213542875636\n",
            "Loss function value:  2.971379308932557\n",
            "Loss function value:  2.2440024381854653\n",
            "Loss function value:  2.904976164765538\n",
            "Loss function value:  2.1276400674303257\n",
            "Loss function value:  2.329668375817627\n",
            "Loss function value:  1.852952809920539\n",
            "Loss function value:  2.882261971647963\n",
            "Loss function value:  2.8302153689332985\n",
            "Loss function value:  1.241881298648121\n",
            "Loss function value:  1.808427275831199\n",
            "Loss function value:  2.103872599099906\n",
            "Loss function value:  2.4782052264066734\n",
            "Loss function value:  2.0719462893703327\n",
            "Loss function value:  2.7952598122861496\n",
            "Loss function value:  2.1983694182014584\n",
            "Loss function value:  2.089213922577994\n",
            "Loss function value:  3.0268783168575477\n",
            "Loss function value:  1.975635730631272\n",
            "Loss function value:  2.6473020029987424\n",
            "Loss function value:  2.2237094217350735\n",
            "Loss function value:  1.9833025245594806\n",
            "Loss function value:  1.5263901870638026\n",
            "Loss function value:  3.133368980473168\n",
            "Loss function value:  3.182330444162512\n",
            "Loss function value:  3.360256387791333\n",
            "Loss function value:  3.0099501836171676\n",
            "Loss function value:  3.5403521564207936\n",
            "Loss function value:  1.4377984333335898\n",
            "Loss function value:  2.926060412704487\n",
            "Loss function value:  2.2901418098985546\n",
            "Loss function value:  2.070217640117816\n",
            "Loss function value:  3.6258215822868127\n",
            "Loss function value:  2.525608368458541\n",
            "Loss function value:  2.557818927688822\n",
            "Loss function value:  1.5611601608744157\n",
            "Loss function value:  2.2443245804513063\n",
            "Loss function value:  2.1022897569287595\n",
            "Loss function value:  3.3083105049654713\n",
            "Loss function value:  2.096016754038166\n",
            "Loss function value:  2.895120988545185\n",
            "Loss function value:  1.7582107091820305\n",
            "Loss function value:  2.647279406968356\n",
            "Loss function value:  2.723051268802405\n",
            "Loss function value:  1.6065211265323713\n",
            "Loss function value:  1.7247372040035973\n",
            "Loss function value:  2.9392571556097713\n",
            "Loss function value:  2.9018578888237627\n",
            "Loss function value:  2.5109712456597206\n",
            "Loss function value:  2.2977393985123467\n",
            "Loss function value:  1.9700827351613588\n",
            "Loss function value:  2.168781491966459\n",
            "Loss function value:  2.3618669936896852\n",
            "Loss function value:  1.9882867090406016\n",
            "Loss function value:  2.784000549784917\n",
            "Loss function value:  3.4382390885207976\n",
            "Loss function value:  1.260459233925675\n",
            "Loss function value:  2.166638943921014\n",
            "Loss function value:  3.36134105925544\n",
            "Loss function value:  2.923532347239498\n",
            "Loss function value:  2.4296025417327187\n",
            "Loss function value:  3.2207493122930084\n",
            "Loss function value:  2.6582246791792725\n",
            "Loss function value:  2.257102393885755\n",
            "Loss function value:  2.4720089869171304\n",
            "Loss function value:  2.215551035095016\n",
            "Loss function value:  1.5146654512425206\n",
            "Loss function value:  2.333122238927051\n",
            "Loss function value:  2.2038751043261673\n",
            "Loss function value:  2.8648968793649585\n",
            "Loss function value:  1.7993269993508665\n",
            "Loss function value:  2.231849178124547\n",
            "Loss function value:  3.5910745575783594\n",
            "Loss function value:  3.046570954055844\n",
            "Loss function value:  3.05647028489658\n",
            "Loss function value:  2.397762484777489\n",
            "Loss function value:  2.908298494682915\n",
            "Loss function value:  2.2189175810969557\n",
            "Loss function value:  3.6792757781893157\n",
            "Loss function value:  2.3985326378664293\n",
            "Loss function value:  2.738409675801937\n",
            "Loss function value:  2.6164724505383328\n",
            "Loss function value:  2.421511624537191\n",
            "Loss function value:  2.840496240632289\n",
            "Loss function value:  2.4060872638842405\n",
            "Loss function value:  2.268072241395049\n",
            "Loss function value:  1.9504103062903098\n",
            "Loss function value:  3.0507626921880253\n",
            "Loss function value:  3.5899856399456045\n",
            "Loss function value:  1.5952136931570777\n",
            "Loss function value:  1.5520756932630233\n",
            "Loss function value:  1.9433890644004486\n",
            "Loss function value:  3.138775301347422\n",
            "Loss function value:  1.931188177674766\n",
            "Loss function value:  3.093536955276653\n",
            "Loss function value:  2.823929507451049\n",
            "Loss function value:  3.064444078257168\n",
            "Loss function value:  2.75155929216643\n",
            "Loss function value:  1.9737860303808714\n",
            "Loss function value:  1.7193373952972943\n",
            "Loss function value:  3.566091625361408\n",
            "Loss function value:  3.327925208625703\n",
            "Loss function value:  3.2927816797379736\n",
            "Loss function value:  1.5842571263574265\n",
            "Loss function value:  3.482340226517755\n",
            "Loss function value:  2.503452161220004\n",
            "Loss function value:  2.676385478186251\n",
            "Loss function value:  2.1840472519555036\n",
            "Loss function value:  2.154024821139811\n",
            "Loss function value:  2.2794940681878066\n",
            "Loss function value:  2.4382517328202176\n",
            "Loss function value:  2.628091775315076\n",
            "Loss function value:  2.153931318353732\n",
            "Loss function value:  2.4640957059958217\n",
            "Loss function value:  2.4718558374631456\n",
            "Loss function value:  2.809948013545281\n",
            "Loss function value:  2.7738738187406144\n",
            "Loss function value:  2.5591970708105602\n",
            "Loss function value:  2.3152184078148945\n",
            "Loss function value:  3.4468105371415825\n",
            "Loss function value:  1.804221745143102\n",
            "Loss function value:  3.4009560438013384\n",
            "Loss function value:  3.202232533359756\n",
            "Loss function value:  2.021118921617641\n",
            "Loss function value:  2.6481065553483303\n",
            "Loss function value:  1.5752456954024405\n",
            "Loss function value:  2.0572283142109002\n",
            "Loss function value:  2.326249906717182\n",
            "Loss function value:  2.761803808477616\n",
            "Loss function value:  1.893288481104244\n",
            "Loss function value:  2.958505596172214\n",
            "Loss function value:  2.1613881896610225\n",
            "Loss function value:  3.0248963697051785\n",
            "Loss function value:  2.359292381798612\n",
            "Loss function value:  2.3061690616799426\n",
            "Loss function value:  2.9416475685458674\n",
            "Loss function value:  2.749195750075493\n",
            "Loss function value:  2.57591468862554\n",
            "Loss function value:  3.1134870175843723\n",
            "Loss function value:  2.1374356586227035\n",
            "Loss function value:  3.2783249482077172\n",
            "Loss function value:  0.9965309486320371\n",
            "Loss function value:  2.000303117013064\n",
            "Loss function value:  3.168001443018181\n",
            "Loss function value:  3.2245592194891883\n",
            "Loss function value:  1.5430481496413575\n",
            "Loss function value:  2.5306746404219274\n",
            "Loss function value:  1.4212405345888284\n",
            "Loss function value:  3.1071848120441294\n",
            "Loss function value:  1.3239326160798692\n",
            "Loss function value:  1.2247432451484888\n",
            "Loss function value:  3.178426581145237\n",
            "Loss function value:  2.407118311983983\n",
            "Loss function value:  2.9677030011163095\n",
            "Loss function value:  3.1654017260194585\n",
            "Loss function value:  2.8279234204848365\n",
            "Loss function value:  3.29637147286146\n",
            "Loss function value:  2.0881825655200643\n",
            "Loss function value:  2.2683330712537844\n",
            "Loss function value:  2.4992112130297652\n",
            "Loss function value:  1.6321756004592956\n",
            "Loss function value:  1.6607076815588504\n",
            "Loss function value:  2.7021990913417135\n",
            "Loss function value:  2.8886429476451245\n",
            "Loss function value:  1.5453079693339313\n",
            "Loss function value:  1.4599543141402613\n",
            "Loss function value:  1.4698967808344463\n",
            "Loss function value:  2.2721798922677463\n",
            "Loss function value:  2.1918015878288464\n",
            "Loss function value:  3.2573004542513537\n",
            "Loss function value:  1.7849971974167445\n",
            "Loss function value:  1.2622071692008277\n",
            "Loss function value:  2.1158500079362663\n",
            "Loss function value:  3.053287956094528\n",
            "Loss function value:  2.145022370906588\n",
            "Loss function value:  2.352937899097701\n",
            "Loss function value:  2.022531383466582\n",
            "Loss function value:  3.121180075193545\n",
            "Loss function value:  1.1857103001158467\n",
            "Loss function value:  3.235707873304021\n",
            "Loss function value:  3.2265140780592136\n",
            "Loss function value:  2.586102117784127\n",
            "Loss function value:  2.435608720329217\n",
            "Loss function value:  2.85530751673272\n",
            "Loss function value:  1.4721597781962388\n",
            "Loss function value:  2.46348427016926\n",
            "Loss function value:  2.6159066088514082\n",
            "Loss function value:  2.949667676373555\n",
            "Loss function value:  2.8043594512349515\n",
            "Loss function value:  1.8777577669446697\n",
            "Loss function value:  1.8863276892798813\n",
            "Loss function value:  2.7230681379044266\n",
            "Loss function value:  3.1562911524521433\n",
            "Loss function value:  1.7577566316355795\n",
            "Loss function value:  2.2820161986119216\n",
            "Loss function value:  1.6295701867070864\n",
            "Loss function value:  2.766851126421064\n",
            "Loss function value:  2.719835962390682\n",
            "Loss function value:  2.735720174603777\n",
            "Loss function value:  2.308814601000139\n",
            "Loss function value:  1.8540470334814405\n",
            "Loss function value:  1.476524891528307\n",
            "Loss function value:  2.933866678986693\n",
            "Loss function value:  2.4626737392722373\n",
            "Loss function value:  1.371932098935257\n",
            "Loss function value:  2.2511703368845275\n",
            "Loss function value:  3.098796164707279\n",
            "Loss function value:  2.8566875363071205\n",
            "Loss function value:  2.5369450737664128\n",
            "Loss function value:  2.2161566885092965\n",
            "Loss function value:  3.4144695340078357\n",
            "Loss function value:  1.9463204652691655\n",
            "Loss function value:  3.030073231445567\n",
            "Loss function value:  2.0809810859400932\n",
            "Loss function value:  2.9165798166306147\n",
            "Loss function value:  2.0309423133584406\n",
            "Loss function value:  3.553918938614682\n",
            "Loss function value:  2.6280136456497183\n",
            "Loss function value:  3.4305393576271945\n",
            "Loss function value:  1.557974279039686\n",
            "Loss function value:  1.9927459362397337\n",
            "Loss function value:  2.6133603034960946\n",
            "Loss function value:  2.1844060275425443\n",
            "Loss function value:  3.4406442889977362\n",
            "Loss function value:  3.240585004315494\n",
            "Loss function value:  3.2361985248616625\n",
            "Loss function value:  2.918918804836272\n",
            "Loss function value:  2.4950528763490425\n",
            "Loss function value:  2.916245931664097\n",
            "Loss function value:  2.4559349449571126\n",
            "Loss function value:  2.1488914958376557\n",
            "Loss function value:  2.5521646268597515\n",
            "Loss function value:  2.786122023745626\n",
            "Loss function value:  3.1308240781947343\n",
            "Loss function value:  2.16084563869219\n",
            "Loss function value:  2.8469210936704865\n",
            "Loss function value:  3.0034346383991517\n",
            "Loss function value:  2.9922674980951736\n",
            "Loss function value:  2.5608243549963143\n",
            "Loss function value:  2.930920932126039\n",
            "Loss function value:  3.0360031453859713\n",
            "Loss function value:  2.0084997413335217\n",
            "Loss function value:  3.353206784456108\n",
            "Loss function value:  2.856895729151696\n",
            "Loss function value:  1.868185500767422\n",
            "Loss function value:  1.828450584911986\n",
            "Loss function value:  2.97664001369462\n",
            "Loss function value:  2.6019732233206434\n",
            "Loss function value:  2.374691097663298\n",
            "Loss function value:  2.3817953708267288\n",
            "Loss function value:  2.686767361618993\n",
            "Loss function value:  2.6914300222828818\n",
            "Loss function value:  3.0132870130268343\n",
            "Loss function value:  1.560700853044423\n",
            "Loss function value:  2.4717604373001745\n",
            "Loss function value:  2.1036847946908552\n",
            "Loss function value:  1.8824560508678227\n",
            "Loss function value:  3.5602665403902214\n",
            "Loss function value:  2.6261188739777364\n",
            "Loss function value:  3.0357730497892135\n",
            "Loss function value:  2.493437140562979\n",
            "Loss function value:  3.0915119789589425\n",
            "Loss function value:  2.775430297242963\n",
            "Loss function value:  1.9133546581369283\n",
            "Loss function value:  1.86176371345312\n",
            "Loss function value:  3.364585533388836\n",
            "Loss function value:  2.4942374418680333\n",
            "Loss function value:  2.9658203436658486\n",
            "Loss function value:  2.940935456005706\n",
            "Loss function value:  2.844066389676828\n",
            "Loss function value:  2.698359972806027\n",
            "Loss function value:  2.2085721967489462\n",
            "Loss function value:  1.9501262697356239\n",
            "Loss function value:  2.9977637160197275\n",
            "Loss function value:  2.8027641104599494\n",
            "Loss function value:  2.0728787801398942\n",
            "Loss function value:  2.164868038744689\n",
            "Loss function value:  2.9812007958623807\n",
            "Loss function value:  2.414779780062608\n",
            "Loss function value:  2.579824584073021\n",
            "Loss function value:  1.8853137199191379\n",
            "Loss function value:  2.2369304898565865\n",
            "Loss function value:  2.0788216921391403\n",
            "Loss function value:  2.1851636715626945\n",
            "Loss function value:  2.1398670168484295\n",
            "Loss function value:  3.483288900346199\n",
            "Loss function value:  3.5012825504909975\n",
            "Loss function value:  2.94743583490482\n",
            "Loss function value:  3.3585839056958973\n",
            "Loss function value:  3.0478831923108287\n",
            "Loss function value:  2.212346907287082\n",
            "Loss function value:  2.107623088645636\n",
            "Loss function value:  1.771789606666487\n",
            "Loss function value:  2.480942556986662\n",
            "Loss function value:  2.4865789207019025\n",
            "Loss function value:  1.5543918412121949\n",
            "Loss function value:  1.4221365283286473\n",
            "Loss function value:  2.9061411182694887\n",
            "Loss function value:  1.8782139624137046\n",
            "Loss function value:  2.1340988987792815\n",
            "Loss function value:  2.4680854763905002\n",
            "Loss function value:  3.5257095261635074\n",
            "Loss function value:  2.065974745970391\n",
            "Loss function value:  1.3801224397556433\n",
            "Loss function value:  1.9495315100646746\n",
            "Loss function value:  2.588939905608409\n",
            "Loss function value:  2.591048195349595\n",
            "Loss function value:  2.079497786967336\n",
            "Loss function value:  2.370676113083793\n",
            "Loss function value:  1.4829610242518347\n",
            "Loss function value:  2.7383726412404013\n",
            "Loss function value:  2.163634556428865\n",
            "Loss function value:  1.8701542209159974\n",
            "Loss function value:  3.3556034357690177\n",
            "Loss function value:  1.925014180505233\n",
            "Loss function value:  2.22921878105436\n",
            "Loss function value:  2.386679973816887\n",
            "Loss function value:  3.1183172789249953\n",
            "Loss function value:  3.5719520438460606\n",
            "Loss function value:  2.739920283324153\n",
            "Loss function value:  2.9650357848350737\n",
            "Loss function value:  3.842991756188686\n",
            "Loss function value:  1.8713827273894768\n",
            "Loss function value:  3.730257414465617\n",
            "Loss function value:  2.4929210357067264\n",
            "Loss function value:  2.855923934525849\n",
            "Loss function value:  2.8477656678077126\n",
            "Loss function value:  2.0733486037052433\n",
            "Loss function value:  2.9224024059258897\n",
            "Loss function value:  2.3349092943183325\n",
            "Loss function value:  2.4445733096714712\n",
            "Loss function value:  2.831471745800117\n",
            "Loss function value:  2.512487100222162\n",
            "Loss function value:  1.9014224394369001\n",
            "Loss function value:  2.510422046867544\n",
            "Loss function value:  2.557697430363228\n",
            "Loss function value:  2.43473785524146\n",
            "Loss function value:  2.026023931645311\n",
            "Loss function value:  2.6443920631044864\n",
            "Loss function value:  1.2078115312678284\n",
            "Loss function value:  1.6039474511134901\n",
            "Loss function value:  3.4641549563386564\n",
            "Loss function value:  3.245030636841392\n",
            "Loss function value:  1.9825420214812268\n",
            "Loss function value:  2.4705849522869974\n",
            "Loss function value:  2.7522148047114894\n",
            "Loss function value:  2.2017480159267473\n",
            "Loss function value:  2.6868079489919108\n",
            "Loss function value:  2.66196609416154\n",
            "Loss function value:  2.8993397086829487\n",
            "Loss function value:  1.7350248740691065\n",
            "Loss function value:  2.597911237175287\n",
            "Loss function value:  2.673825595801418\n",
            "Loss function value:  2.126773715859169\n",
            "Loss function value:  2.317500465445785\n",
            "Loss function value:  3.0460123025028287\n",
            "Loss function value:  3.0126229676802483\n",
            "Loss function value:  2.331041538423475\n",
            "Loss function value:  2.1442749588454877\n",
            "Loss function value:  1.8706518425246237\n",
            "Loss function value:  1.9263722134717836\n",
            "Loss function value:  1.427473141996334\n",
            "Loss function value:  2.652974266537443\n",
            "Loss function value:  3.627806336993808\n",
            "Loss function value:  2.2655804174616065\n",
            "Loss function value:  2.5393212591122842\n",
            "Loss function value:  1.8679151248501815\n",
            "Loss function value:  2.0439545825490146\n",
            "Loss function value:  2.727160693580013\n",
            "Loss function value:  2.589945247811176\n",
            "Loss function value:  2.2501261339415635\n",
            "Loss function value:  3.1123547885421723\n",
            "Loss function value:  2.4821306095334514\n",
            "Loss function value:  3.2418776625542063\n",
            "Loss function value:  2.8752595204814115\n",
            "Loss function value:  2.4137218876458526\n",
            "Loss function value:  2.27900102310422\n",
            "Loss function value:  1.9663306966481287\n",
            "Loss function value:  1.2982798941748281\n",
            "Loss function value:  2.9949749534692733\n",
            "Loss function value:  1.7678059909607307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3gMU3wmSWKx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}